{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd27f2dd",
   "metadata": {},
   "source": [
    "# Part I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03024055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for scaling images\n",
    "def scale_images(images, scale=[-1, 1]):\n",
    "    # convert from unit8 to float32\n",
    "    converted_images = images.astype('float32')\n",
    "    # scale\n",
    "    min_value = converted_images.max()\n",
    "    max_value = converted_images.min()\n",
    "    average_value = (max_value - min_value) / (scale[1] - scale[0])\n",
    "    converted_images = (images - min_value) / average_value + scale[0]\n",
    "    return converted_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33c194cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating points in latent space as input for the generator\n",
    "def generate_latent_points(latent_dim, n_samples):\n",
    "    from numpy.random import randn\n",
    "    # generate points in the latent space and reshape into a batch of inputs for the network\n",
    "    return randn(latent_dim * n_samples).reshape((n_samples, latent_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72486752",
   "metadata": {},
   "source": [
    "# Part II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea609fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating generator\n",
    "def define_gan(g_model, d_model, optimizer, loss='binary_crossentropy'):\n",
    "    from keras.models import Sequential\n",
    "    # make weights in the discriminator not trainable\n",
    "    d_model.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(g_model)\n",
    "    # add discriminator\n",
    "    model.add(d_model)\n",
    "    # compile model\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1827ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(g_model, laten_dim, n_samples):\n",
    "    from numpy import zeros\n",
    "    # generate points in latent space\n",
    "    x_input = generate_latent_points(latent_dim, n_samples)\n",
    "    # predict outputs\n",
    "    x = g_model.predict(x_input)\n",
    "    # create 'fake' class labels (0)\n",
    "    y = zeros((n_samples, 1))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "328b5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real samples from dataset\n",
    "def generate_real_samples(dataset, n_samples):\n",
    "    from numpy import ones\n",
    "    # choose random instances\n",
    "    ix = randint(0, dataset.shape[0], n_samples)\n",
    "    # retrieve selected images\n",
    "    x = dataset[ix]\n",
    "    # generate 'real' class labels (1)\n",
    "    y = ones((n_samples, 1))\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c075c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator models\n",
    "def train(g_model, d_model, gan_model, dataset, laten_dim, n_epochs=100, n_batch=128, do_print=True):\n",
    "    from numpy import ones\n",
    "    batch_per_epoch = int(dataset.shape[0] / n_batch)\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # enumerate batches over the training set\n",
    "        for j in range(batch_per_epoch):\n",
    "            # get randomly selected 'real' samples\n",
    "            x_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "            # update discriminator model weights\n",
    "            d_loss1, _ = d_model.train_on_batch(x_real, y_real)\n",
    "            # generate 'fake' samples\n",
    "            x_fake, y_fake = generate_fake_samples(dataset, half_batch)\n",
    "            # update discriminator model weights\n",
    "            d_loss2, _ = d_model.train_on_batch(x_fake, y_fake)\n",
    "            # prepare points in latent space as input for the generator\n",
    "            x_gan = generate_latent_points(latent_dim, n_batch)\n",
    "            # create inverted labels for the fake samples\n",
    "            y_gan = ones((n_batch, 1))\n",
    "            # update the generator via the discriminator's error\n",
    "            g_loss = gan_model.train_on_batch(x_gan, y_gan)\n",
    "            if do_print:\n",
    "                # summarize loss on this batch\n",
    "                print(f'>{i+1:03d} {j+1:03d}/{n_batch}, d1={d_loss1:.3f}, d2{d_loss2:.3f}, g={g_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a90b12ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform interpolate between two points in latent space\n",
    "def interpolate_points(p1, p2, intrpl, n_steps=10):\n",
    "    from numpy import linspace, asarray\n",
    "    # interpolate ratios betweem the points\n",
    "    ratios = linspace(0, 1, num=n_steps)\n",
    "    # linear interpolate vectors\n",
    "    vectors = list()\n",
    "    for ratio in rations:\n",
    "        v = intrpl(ratio, p1, p2)\n",
    "        vectors.append(v)\n",
    "    return asarray(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2894fe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spherical linear interpolation (slerp)\n",
    "def slerp(val, low, high):\n",
    "    from numpy import arccos, clip, dot, sim\n",
    "    from numpy.linalg import norm\n",
    "    omega = arccos(clip(dot(low/norm(low), high/norm(high)), -1, 1))\n",
    "    so = sin(omega)\n",
    "    if so == 0:\n",
    "        # L'Hopital's rule/LERP\n",
    "        return (1.0-val)*low + val*high\n",
    "    return sin((1.0-val)*omega) / so*low + sin(val*omega) / so * high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa00ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uniform interpolation (uni_inter)\n",
    "def uni_inter(val, low, high):\n",
    "    return (1.0-val)*p1 + val*p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4283836f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# average list of latent space vectors\n",
    "def average_points(points, ix):\n",
    "    from numpy import vstack\n",
    "    # convert to zero offset points\n",
    "    zero_ix = [i-1 for i in ix]\n",
    "    # retreive required points\n",
    "    vectors = points[zero_ix]\n",
    "    # average the vectors\n",
    "    avg_vector = mean(vectors, axis=0)\n",
    "    # combine original and avg vectors\n",
    "    all_vectors = vstack((vectors, avg_vector))\n",
    "    return all_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0f7083",
   "metadata": {},
   "source": [
    "# Part III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480e0dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the inception score for p(y|x)\n",
    "def calculate_inception_score(p_yx, eps=1e-16):\n",
    "    from numpy import expand_dims, log, mean, exp\n",
    "    # calculate p(y)\n",
    "    p_y = expand_dims(p_yx.mean(axis=0), 0)\n",
    "    # kl divergence for each image\n",
    "    kl_d = p_yx*(log(p_yx+eps)-log(p_y+eps))\n",
    "    # sum over classes\n",
    "    sum_kl_d = kl_d.sum(axis=1)\n",
    "    # average over images\n",
    "    avg_kl_d = mean(sum_kl_d)\n",
    "    # undo the logs\n",
    "    is_score = exp(avg_kld)\n",
    "    return is_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abc967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale an array of images to a new size\n",
    "def scale_images(imahes, new_shape):\n",
    "    from numpy import asarray\n",
    "    from skimage.transform import resize\n",
    "    images_list = list()\n",
    "    for image in images:\n",
    "        # resize with nearest neighbot interpolation\n",
    "        new_image = resize(image, new_shape, 0)\n",
    "        # store\n",
    "        images_list.append(new_image)\n",
    "    return asarray(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c2978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assume images have any shape and pixels in [0, 255]\n",
    "def calculate_inception_score(images, n_split=10, eps=1e-16):\n",
    "    from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "    from numpy import expand_dims\n",
    "    # load inception v3 model\n",
    "    # enumerate splits of images/predictions\n",
    "    scores = list()\n",
    "    n_part = floor(images.shape[0]/n_split)\n",
    "    for i in range(n_split):\n",
    "        # retriece images\n",
    "        ix_start, ix_end = i*n_part, (i+1)*n_part\n",
    "        subset = images[ix_start:ix_end]\n",
    "        # convert from unit8 to float32\n",
    "        subset = subset.astype('float32')\n",
    "        # scale images to the required size\n",
    "        subset = scale_images(subset, (299, 299, 3))\n",
    "        # pre-process images, scale [-1, 1]\n",
    "        sunset = preprocess_input(subset)\n",
    "        # predict p(y|x)\n",
    "        p_yx = model.predict(subset)\n",
    "        # calculate p(y)\n",
    "        p_y = expand_dim()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ai] *",
   "language": "python",
   "name": "conda-env-ai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
